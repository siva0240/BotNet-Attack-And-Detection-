{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba178799"
      },
      "source": [
        "# Install libraries"
      ],
      "id": "ba178799"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUyg9shEYajd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "CUyg9shEYajd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GrPcDRdYjGx"
      },
      "outputs": [],
      "source": [],
      "id": "2GrPcDRdYjGx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa695fd9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import warnings\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dropout, Activation, Dense, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import time\n",
        "import joblib\n",
        "\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "id": "fa695fd9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20ae3abc"
      },
      "source": [
        "# Read the Excel file into a Pandas DataFrame"
      ],
      "id": "20ae3abc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50034a89"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/dataset iot/iot23_combined.csv\")"
      ],
      "id": "50034a89"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "417a6793"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ],
      "id": "417a6793"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "203f76bb"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ],
      "id": "203f76bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e19a4f6e"
      },
      "source": [
        "# Show the unique values of the type of attacks"
      ],
      "id": "e19a4f6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b411b330"
      },
      "outputs": [],
      "source": [
        "data.label.unique()"
      ],
      "id": "b411b330"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cc16851"
      },
      "source": [
        "# Count the frequencies of the type of attack"
      ],
      "id": "1cc16851"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af386c69"
      },
      "outputs": [],
      "source": [
        "data['label'].value_counts()"
      ],
      "id": "af386c69"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d933e94"
      },
      "source": [
        "# Plot the frequencies of every type of attack"
      ],
      "id": "3d933e94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "045dabad"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='label', data=data)\n",
        "plt.xticks(rotation=60)\n",
        "plt.show()\n"
      ],
      "id": "045dabad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93f7a5d1"
      },
      "source": [
        "## Clean the data"
      ],
      "id": "93f7a5d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40beae3c"
      },
      "outputs": [],
      "source": [
        "data['label'].replace({'-   Benign   -': 'Benign', 'Benign ': 'Benign'}, inplace=True)\n"
      ],
      "id": "40beae3c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88dc0d25"
      },
      "outputs": [],
      "source": [
        "data['label'].unique()"
      ],
      "id": "88dc0d25"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2781209c"
      },
      "source": [
        "# Feature Engineering"
      ],
      "id": "2781209c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5460e94a"
      },
      "outputs": [],
      "source": [
        "data['label'].replace({'C&C-HeartBeat': 'C&C',\n",
        "                       'C&C-Torii': 'C&C',\n",
        "                        'C&C-FileDownload': 'C&C',\n",
        "                        'C&C-HeartBeat-FileDownload':'C&C',\n",
        "                        'C&C-Mirai': 'C&C'}, inplace=True)\n"
      ],
      "id": "5460e94a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6714e5dc"
      },
      "outputs": [],
      "source": [
        "data.label.unique()"
      ],
      "id": "6714e5dc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee73d91d"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='label', data=data)\n",
        "plt.xticks(rotation=60)\n",
        "plt.show()\n"
      ],
      "id": "ee73d91d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8fe86c5"
      },
      "source": [
        "# Drop columns that are unessary"
      ],
      "id": "f8fe86c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8c576a2"
      },
      "outputs": [],
      "source": [
        "del data['Unnamed: 0']"
      ],
      "id": "f8c576a2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c7f184e"
      },
      "outputs": [],
      "source": [
        "# del data['id.orig_h']"
      ],
      "id": "1c7f184e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e221189"
      },
      "outputs": [],
      "source": [
        "# del data['ts']"
      ],
      "id": "4e221189"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b03741c7"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ],
      "id": "b03741c7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a045e5a7"
      },
      "source": [
        "# Check for duplication"
      ],
      "id": "a045e5a7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0db95537"
      },
      "outputs": [],
      "source": [
        "# Step 1: Check for duplicated rows\n",
        "duplicates = data.duplicated()\n",
        "\n",
        "# Step 2: Count the occurrences of duplicates\n",
        "duplicate_counts = duplicates.sum()\n",
        "print(\"Number of duplicated rows:\", duplicate_counts)\n"
      ],
      "id": "0db95537"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ac34928",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# Step 3: Remove duplicated rows\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "# Step 4: Verify that duplicates have been removed\n",
        "duplicates_after_removal = data.duplicated().sum()\n",
        "print(\"Number of duplicated rows after removal:\", duplicates_after_removal)\n"
      ],
      "id": "5ac34928"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdc35734"
      },
      "outputs": [],
      "source": [
        "data"
      ],
      "id": "bdc35734"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f01e5b41"
      },
      "source": [
        "# Remove illogical data"
      ],
      "id": "f01e5b41"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG2pc0jpy5bV"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ],
      "id": "yG2pc0jpy5bV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ffc9e1c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "data.duration.unique()"
      ],
      "id": "8ffc9e1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5d28d5d"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = data[(data['duration'] >= 0)]\n",
        "\n",
        "#  Print the resulting dataset\n",
        "data.duration.unique()\n"
      ],
      "id": "f5d28d5d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3963fe1"
      },
      "source": [
        "# Save the cleaned data"
      ],
      "id": "d3963fe1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68bffeb8"
      },
      "outputs": [],
      "source": [
        "data.to_csv('/content/drive/MyDrive/dataset iot/cleaned_data.csv', index=False)"
      ],
      "id": "68bffeb8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c4150ea"
      },
      "source": [
        "# Building The Classification Models\n",
        "\n",
        "#### Classification models(Support Vector machine & Naive Bayes)"
      ],
      "id": "1c4150ea"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59c84425"
      },
      "source": [
        "# Support Vector machine (SVM)"
      ],
      "id": "59c84425"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e35a2a01"
      },
      "source": [
        "# Train the SVM model"
      ],
      "id": "e35a2a01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ce581de"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/drive/MyDrive/dataset iot/cleaned_data.csv\"\n",
        "SVM = pd.read_csv(filepath, nrows=27000)"
      ],
      "id": "5ce581de"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5eaf233"
      },
      "outputs": [],
      "source": [
        "SVM.shape"
      ],
      "id": "e5eaf233"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fac38049"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the features and target\n",
        "features = ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']\n",
        "target = 'label'\n",
        "\n",
        "# Load the data\n",
        "X = SVM[features]\n",
        "Y = SVM[target]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=10, test_size=0.2)\n",
        "\n",
        "# Create the SVM classifier model and fit it to the training data\n",
        "SVM_classifier = SVC(C=1.0, cache_size=1500, verbose=True)\n",
        "SVM_classifier.fit(X_train, Y_train)\n",
        "\n",
        "# Evaluate the model on the testing data\n",
        "score = SVM_classifier.score(X_test, Y_test)\n",
        "print('Model Accuracy: ', score)\n",
        "print()\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = SVM_classifier.predict(X_test)\n",
        "\n",
        "# Suppress the UndefinedMetricWarning\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.metrics')\n",
        "\n",
        "# Calculate the classification report of the model\n",
        "report = classification_report(Y_test, y_pred, zero_division=0)\n",
        "print('Classification Report:')\n",
        "print(report)\n",
        "print()\n",
        "\n",
        "# Calculate the time taken by the model to run\n",
        "start_time = time.time()\n",
        "print()\n",
        "end_time = time.time()\n",
        "print('Time taken: ', end_time - start_time, 'seconds')\n"
      ],
      "id": "fac38049"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3u7xfa_hZAIN"
      },
      "outputs": [],
      "source": [],
      "id": "3u7xfa_hZAIN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd284f28"
      },
      "source": [
        "[link text](https://)# Train the Naive Bayse model\n",
        "\n",
        "### Read the data"
      ],
      "id": "fd284f28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bed58610"
      },
      "outputs": [],
      "source": [
        "#filepath = \"/kaggle/input/iot23-dataset/cleaned_data.csv\"\n",
        "\n",
        "NP = pd.read_csv(filepath, nrows=27000)"
      ],
      "id": "bed58610"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2a5be02"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = NP[['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']]\n",
        "Y = NP['label']\n",
        "\n",
        "# Normalize the features\n",
        "scaler = MinMaxScaler()\n",
        "normalized_X = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(normalized_X, Y, random_state=100, test_size=0.2)\n",
        "\n",
        "# Suppress the UndefinedMetricWarning\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.metrics')\n",
        "\n",
        "clf = GaussianNB()\n",
        "\n",
        "start = time.time()\n",
        "print('program start...')\n",
        "print()\n",
        "\n",
        "clf.fit(X_train, Y_train)\n",
        "print()\n",
        "print(clf.score(X_test, Y_test))\n",
        "print()\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(y_pred)\n",
        "print()\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(end - start, 'seconds')\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(Y_test, y_pred))\n"
      ],
      "id": "f2a5be02"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b50fa334"
      },
      "source": [
        "\n",
        "\n",
        "## Classification models( Decision Tree & Neural Networks)\n",
        "\n",
        "### Read the dataframe\n"
      ],
      "id": "b50fa334"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8735030"
      },
      "outputs": [],
      "source": [
        "#filepath = \"/kaggle/input/iot23-dataset/cleaned_data.csv\"\n",
        "DS = pd.read_csv(filepath, nrows=27000)"
      ],
      "id": "f8735030"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0fac799"
      },
      "source": [
        "# Train Decision Tree Model"
      ],
      "id": "b0fac799"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "655e8f3f"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "# Select features and target variable\n",
        "features = ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']\n",
        "target = 'label'\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(DS[features], DS[target], random_state=5, test_size=0.2)\n",
        "\n",
        "# Create Decision Tree classifier\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "start = time.time()\n",
        "print('program start...')\n",
        "print()\n",
        "\n",
        "# Fit the model\n",
        "classifier.fit(X_train, Y_train)\n",
        "print()\n",
        "\n",
        "# Evaluate the model\n",
        "score = classifier.score(X_test, Y_test)\n",
        "print(score)\n",
        "print()\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(y_pred)\n",
        "print()\n",
        "\n",
        "end = time.time()\n",
        "print('program end...')\n",
        "print()\n",
        "print('time cost: ')\n",
        "print(end - start, 'seconds')\n",
        "\n",
        "# Suppress the UndefinedMetricWarning\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn.metrics')\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(Y_test, y_pred))\n"
      ],
      "id": "655e8f3f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce133db3"
      },
      "source": [
        "# Train CNN  Model"
      ],
      "id": "ce133db3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75f9d85e"
      },
      "outputs": [],
      "source": [
        "# filepath = \"/kaggle/input/iot23-dataset/cleaned_data.csv\"\n",
        "CNN = pd.read_csv(filepath)\n"
      ],
      "id": "75f9d85e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "971ca49e"
      },
      "source": [
        "# Set features"
      ],
      "id": "971ca49e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33090cd1"
      },
      "outputs": [],
      "source": [
        "X = CNN[['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']].values"
      ],
      "id": "33090cd1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d34af7f"
      },
      "source": [
        "# Encode the target variable"
      ],
      "id": "0d34af7f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d2ec127"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "CNN['label'] = le.fit_transform(CNN['label'])\n"
      ],
      "id": "8d2ec127"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19e78faa"
      },
      "outputs": [],
      "source": [
        "CNN['label']"
      ],
      "id": "19e78faa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "008f3462"
      },
      "outputs": [],
      "source": [
        "CNN['label'].unique()"
      ],
      "id": "008f3462"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f298695"
      },
      "outputs": [],
      "source": [
        "#define the features and target\n",
        "features = ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']\n",
        "target = 'label'\n",
        "\n",
        "#load the data\n",
        "X = CNN[features]\n",
        "Y = CNN[target]"
      ],
      "id": "3f298695"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e170fa7"
      },
      "outputs": [],
      "source": [
        "Y = pd.get_dummies(CNN['label']).values"
      ],
      "id": "2e170fa7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "573cb9c1"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ],
      "id": "573cb9c1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1396f54"
      },
      "source": [
        "# Scale the features"
      ],
      "id": "c1396f54"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3166a611"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "id": "3166a611"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e161175f"
      },
      "outputs": [],
      "source": [
        "scaler.fit(X)"
      ],
      "id": "e161175f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58b782f5"
      },
      "outputs": [],
      "source": [
        "normalized_x = scaler.transform(X)"
      ],
      "id": "58b782f5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bad985d0"
      },
      "outputs": [],
      "source": [
        "normalized_x"
      ],
      "id": "bad985d0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec2a849b"
      },
      "outputs": [],
      "source": [
        "normalized_x.shape"
      ],
      "id": "ec2a849b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "888e488a"
      },
      "outputs": [],
      "source": [
        "scaler.fit(Y)"
      ],
      "id": "888e488a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a51b7cc"
      },
      "outputs": [],
      "source": [
        "normalized_y = scaler.transform(Y)"
      ],
      "id": "7a51b7cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1690892"
      },
      "outputs": [],
      "source": [
        "normalized_y"
      ],
      "id": "b1690892"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "932288b9"
      },
      "source": [
        "# Conficure the archetucture of the CNN Model"
      ],
      "id": "932288b9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90056d03"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(normalized_x, normalized_y, random_state=10, test_size=0.2)"
      ],
      "id": "90056d03"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87905526"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ],
      "id": "87905526"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c9397ad"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "id": "2c9397ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5e0f259",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Define the features and target\n",
        "features = ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts',\n",
        "            'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ',\n",
        "            'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0',\n",
        "            'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']\n",
        "target = 'label'\n",
        "\n",
        "\n",
        "# Encode the target variable\n",
        "le = LabelEncoder()\n",
        "data['label'] = le.fit_transform(data['label'])\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X = data[features]\n",
        "Y = data[target]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert the target variable to categorical\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)\n",
        "\n",
        "# Configure the architecture of the CNN model\n",
        "model = Sequential()\n",
        "model.add(Dense(2000, activation='relu', input_dim=len(features)))\n",
        "model.add(Dense(1500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(800, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(150, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(le.classes_), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "start = time.time()\n",
        "print('Program start...')\n",
        "print()\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=10, batch_size=256, validation_data=(X_test, Y_test), verbose=1)\n",
        "print()\n",
        "\n",
        "end = time.time()\n",
        "print('Program end...')\n",
        "print()\n",
        "print('Time cost: ')\n",
        "print(end - start, 'seconds')\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test Accuracy:', test_accuracy)\n"
      ],
      "id": "c5e0f259"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI2vjfQtfATN"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/model1_dl.h5')"
      ],
      "id": "aI2vjfQtfATN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6aLS7CzfI6r"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/mode1_dl_keras')"
      ],
      "id": "L6aLS7CzfI6r"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17a0516a"
      },
      "source": [
        "# Save the model with the highest accuracy\n",
        "\n",
        "Since the desition tree model is the model with the highest classification accuracy, we will save it as .pkl"
      ],
      "id": "17a0516a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56f6560a"
      },
      "source": [
        "# Save it into a pkl"
      ],
      "id": "56f6560a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a1fa460"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "id": "7a1fa460"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f3d0830"
      },
      "outputs": [],
      "source": [
        "# Select features and target variable\n",
        "features = ['duration', 'orig_bytes', 'resp_bytes', 'missed_bytes', 'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes', 'proto_icmp', 'proto_tcp', 'proto_udp', 'conn_state_OTH', 'conn_state_REJ', 'conn_state_RSTO', 'conn_state_RSTOS0', 'conn_state_RSTR', 'conn_state_RSTRH', 'conn_state_S0', 'conn_state_S1', 'conn_state_S2', 'conn_state_S3', 'conn_state_SF', 'conn_state_SH', 'conn_state_SHR']\n",
        "target = 'label'\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(DS[features], DS[target], random_state=5, test_size=0.2)\n",
        "\n",
        "# Create pipeline with Decision Tree classifier\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', DecisionTreeClassifier())\n",
        "])\n",
        "\n",
        "# Fit the model using the pipeline\n",
        "pipeline.fit(X_train, Y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = pipeline.score(X_test, Y_test)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(Y_test, y_pred))\n",
        "\n",
        "# Save the pipeline as a .pkl file\n",
        "filename = 'decision_tree_pipeline.pkl'\n",
        "joblib.dump(pipeline, filename)\n",
        "print(\"Pipeline saved as\", filename)\n"
      ],
      "id": "9f3d0830"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H7UrSTKfpqI"
      },
      "outputs": [],
      "source": [],
      "id": "4H7UrSTKfpqI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dplwe5aNfo1b"
      },
      "outputs": [],
      "source": [
        "result = model.predict([[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]])\n",
        "print(np.argmax(result))"
      ],
      "id": "Dplwe5aNfo1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGFYy4WWZwGi"
      },
      "outputs": [],
      "source": [
        "pip install gradio"
      ],
      "id": "KGFYy4WWZwGi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEg0J6jHZtYk"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ],
      "id": "WEg0J6jHZtYk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1W1sPUIaMsT"
      },
      "outputs": [],
      "source": [],
      "id": "j1W1sPUIaMsT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G477t5UaCF2"
      },
      "outputs": [],
      "source": [
        "def predict(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x):\n",
        "  # Scale the features\n",
        "  #scaler = MinMaxScaler()\n",
        "  #Z_test = scaler.transform([[a,b,c,d,e,f,g,h,i]])\n",
        "  Z_test=[a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x]\n",
        "  r = model.predict(Z_test)\n",
        "  return r"
      ],
      "id": "7G477t5UaCF2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn5f-9IoZxuG"
      },
      "outputs": [],
      "source": [
        "demo=gr.interface(fn=predict, inputs=[\"text\", \"text\", \"text\", \"text\", \"text\", \"text\",\"text\", \"text\", \"text\", \"text\", \"text\", \"text\",\"text\", \"text\", \"text\", \"text\", \"text\", \"text\",\"text\", \"text\", \"text\", \"text\", \"text\", \"text\"],\n",
        "             outputs=\"label\")\n",
        "demo.launch(debug=True)"
      ],
      "id": "gn5f-9IoZxuG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b9ce419e",
        "outputId": "3727c5d5-a6b5-4617-f2cd-c3d2b15f8c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://0e5d7a3dc9efd7504c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0e5d7a3dc9efd7504c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 288, in __getitem__\n",
            "    name, est = self.steps[ind]\n",
            "TypeError: list indices must be integers or slices, not str\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 253, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1695, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1235, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 692, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-63-d6747bb7845c>\", line 12, in predict_outcome\n",
            "    data = pd.DataFrame([[0]*len(model['feature_names'])],\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 291, in __getitem__\n",
            "    return self.named_steps[ind]\n",
            "KeyError: 'feature_names'\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Load the model\n",
        "model = joblib.load(\"/content/decision_tree_pipeline.pkl\")\n",
        "\n",
        "# Define the function to make predictions\n",
        "def predict_outcome(feature1, feature2, feature3, feature4, feature5):\n",
        "    # Create a DataFrame with the input features\n",
        "    data = pd.DataFrame([[0]*len(model['feature_names'])],\n",
        "                        columns=model['feature_names'])\n",
        "    data['feature1'] = feature1\n",
        "    data['feature2'] = feature2\n",
        "    data['feature3'] = feature3\n",
        "    data['feature4'] = feature4\n",
        "    data['feature5'] = feature5\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(data)\n",
        "\n",
        "    # Return the predicted outcome\n",
        "    return prediction[0]\n",
        "\n",
        "# Create the Gradio interface\n",
        "iface = gr.Interface(fn=predict_outcome,\n",
        "                     inputs=[gr.Number(label=\"Feature 1\"),\n",
        "                             gr.Number(label=\"Feature 2\"),\n",
        "                             gr.Number(label=\"Feature 3\"),\n",
        "                             gr.Number(label=\"Feature 4\"),\n",
        "                             gr.Number(label=\"Feature 5\")],\n",
        "                     outputs=gr.Textbox(label=\"Predicted Outcome\"))\n",
        "\n",
        "# Launch the interface\n",
        "iface.launch(debug=True)\n"
      ],
      "id": "b9ce419e"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 176.362677,
      "end_time": "2023-05-20T20:58:31.786325",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-05-20T20:55:35.423648",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}